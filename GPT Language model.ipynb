{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9003231,"sourceType":"datasetVersion","datasetId":5423747}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-27T14:13:30.629804Z","iopub.execute_input":"2024-07-27T14:13:30.630470Z","iopub.status.idle":"2024-07-27T14:13:30.642820Z","shell.execute_reply.started":"2024-07-27T14:13:30.630445Z","shell.execute_reply":"2024-07-27T14:13:30.641816Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"device =  \"cuda\" if torch.cuda.is_available() else \"cpu\" \ndevice","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:13:30.643897Z","iopub.execute_input":"2024-07-27T14:13:30.644208Z","iopub.status.idle":"2024-07-27T14:13:30.658432Z","shell.execute_reply.started":"2024-07-27T14:13:30.644180Z","shell.execute_reply":"2024-07-27T14:13:30.657479Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}]},{"cell_type":"code","source":"block_size = 128\nbatch_size = 16\nlearning_rate = 1e-5\nmax_iter = 30000\neval_iters = 250\nn_embed = 384\nn_head = 6\ndropout = 0.2\nn_layer = 6","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:14:03.697711Z","iopub.execute_input":"2024-07-27T14:14:03.698515Z","iopub.status.idle":"2024-07-27T14:14:03.703934Z","shell.execute_reply.started":"2024-07-27T14:14:03.698473Z","shell.execute_reply":"2024-07-27T14:14:03.702968Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/input/wizard-of-oz-txt/wizard_of_oz.txt\", \"r\", encoding=\"utf-8\") as f:\n  text = f.read()","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:14:03.944618Z","iopub.execute_input":"2024-07-27T14:14:03.944892Z","iopub.status.idle":"2024-07-27T14:14:03.949957Z","shell.execute_reply.started":"2024-07-27T14:14:03.944868Z","shell.execute_reply":"2024-07-27T14:14:03.949066Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"chars = sorted(set(text))\nvocab_size = len(chars)\nprint(chars)\nprint(len(chars))","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:14:04.136357Z","iopub.execute_input":"2024-07-27T14:14:04.137035Z","iopub.status.idle":"2024-07-27T14:14:04.145643Z","shell.execute_reply.started":"2024-07-27T14:14:04.137008Z","shell.execute_reply":"2024-07-27T14:14:04.144710Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"['\\n', ' ', '!', '\"', '&', \"'\", '(', ')', '*', ',', '-', '.', '0', '1', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n74\n","output_type":"stream"}]},{"cell_type":"code","source":"string_to_int = {ch: i for i, ch in enumerate(chars)}\nint_to_string = {i: ch for i, ch in enumerate(chars)}","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:14:04.318022Z","iopub.execute_input":"2024-07-27T14:14:04.318272Z","iopub.status.idle":"2024-07-27T14:14:04.322650Z","shell.execute_reply.started":"2024-07-27T14:14:04.318250Z","shell.execute_reply":"2024-07-27T14:14:04.321770Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"encode = lambda s: [string_to_int[ch] for ch in s]\ndecode = lambda l: \"\".join([int_to_string[i] for i in l])","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:14:04.491919Z","iopub.execute_input":"2024-07-27T14:14:04.492178Z","iopub.status.idle":"2024-07-27T14:14:04.496513Z","shell.execute_reply.started":"2024-07-27T14:14:04.492154Z","shell.execute_reply":"2024-07-27T14:14:04.495626Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"data = torch.tensor(encode(text), dtype=torch.long)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:14:04.672258Z","iopub.execute_input":"2024-07-27T14:14:04.672590Z","iopub.status.idle":"2024-07-27T14:14:04.724853Z","shell.execute_reply.started":"2024-07-27T14:14:04.672565Z","shell.execute_reply":"2024-07-27T14:14:04.724188Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"n = int(0.8*len(data))\ntrain_data = data[:n]\nval_data = data[n:]","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:14:04.853191Z","iopub.execute_input":"2024-07-27T14:14:04.853475Z","iopub.status.idle":"2024-07-27T14:14:04.857992Z","shell.execute_reply.started":"2024-07-27T14:14:04.853452Z","shell.execute_reply":"2024-07-27T14:14:04.857115Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"def get_batch(split):\n  data = train_data if split == \"train\" else val_data\n  idx  = torch.randint(len(data) - block_size, (batch_size,))\n  x = torch.stack([data[i:i+block_size] for i in idx])\n  y = torch.stack([data[i+1:i+block_size+1] for i in idx])\n  x, y = x.to(device), y.to(device)\n  return x, y","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:14:05.042387Z","iopub.execute_input":"2024-07-27T14:14:05.042633Z","iopub.status.idle":"2024-07-27T14:14:05.048267Z","shell.execute_reply.started":"2024-07-27T14:14:05.042612Z","shell.execute_reply":"2024-07-27T14:14:05.047445Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"x, y = get_batch(\"train\")","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:14:05.227549Z","iopub.execute_input":"2024-07-27T14:14:05.227812Z","iopub.status.idle":"2024-07-27T14:14:05.433630Z","shell.execute_reply.started":"2024-07-27T14:14:05.227790Z","shell.execute_reply":"2024-07-27T14:14:05.432807Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef estimate_loss():\n  out = {}\n  model.eval()\n  for split in [\"train\", \"val\"]:\n    losses = torch.zeros(eval_iters)\n    for k in range(eval_iters):\n      X, Y = get_batch(split)\n      logits, loss = model(X, Y)\n      losses[k] = loss.item()\n    out[split] = losses.mean()\n  model.train()\n  return out","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:14:05.435056Z","iopub.execute_input":"2024-07-27T14:14:05.435356Z","iopub.status.idle":"2024-07-27T14:14:05.441282Z","shell.execute_reply.started":"2024-07-27T14:14:05.435331Z","shell.execute_reply":"2024-07-27T14:14:05.440461Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"class Head(nn.Module):\n    \n    def __init__(self, head_size):\n        super().__init__()\n        self.key = nn.Linear(n_embed, head_size, bias=False)\n        self.query = nn.Linear(n_embed, head_size, bias=False)\n        self.values = nn.Linear(n_embed, head_size, bias=False)\n        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        B, T, C = x.shape\n        k = self.key(x)\n        q = self.query(x)\n        \n        wei = q @ k.transpose(-2, -1) * k.shape[-1] ** -0.5\n        wei = wei.masked_fill(self.tril[:T, :T] == 0, float(\"-inf\"))\n        wei = F.softmax(wei, dim=-1)\n        wei = self.dropout(wei)\n        \n        v = self.values(x)\n        out = wei @ v\n        return out\n        \nf\nclass MultiHeadAttention(nn.Module):\n    \n    def __init__(self, num_heads, head_size):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        self.linear = nn.Linear(head_size * num_heads, n_embed)\n        self.dropout = nn.Dropout(dropout)\n    \n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n        out = self.dropout(self.linear(out))\n        return out\n\nclass FeedForward(nn.Module):\n    \n    def __init__(self, n_embed):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(n_embed, 4*n_embed),\n            nn.ReLU(),\n            nn.Linear(4*n_embed, n_embed),\n            nn.Dropout(dropout),\n        )\n    def forward(self, x):\n        return self.net(x)\n\nclass Block(nn.Module):\n    \n    def __init__(self, n_embed, n_head):\n        super().__init__()\n        head_size = n_embed // n_head\n        self.sa = MultiHeadAttention(n_head, head_size)\n        self.ffwd = FeedForward(n_embed)\n        self.ln1 = nn.LayerNorm(n_embed)\n        self.ln2 = nn.LayerNorm(n_embed)\n        \n    def forward(self,x):\n        y = self.sa(x)\n        x = self.ln1(x+y)\n        y = self.ffwd(x)\n        x = self.ln2(x+y)\n        return x\n\nclass GPTLanguageModel(nn.Module):\n    def __init__(self, vocab_size):\n        super().__init__()\n        self.token_embedding_table = nn.Embedding(vocab_size, n_embed)\n        self.position_embedding_table = nn.Embedding(block_size, n_embed)\n        self.blocks = nn.Sequential(*[Block(n_embed, n_head=n_head) for _ in range(n_layer)])\n\n\n        self.ln_f = nn.LayerNorm(n_embed)\n        self.lm_head = nn.Linear(n_embed, vocab_size)\n        self.apply(self.__init_weights)\n\n\n    def __init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n            if module.bias is not None:\n                torch.nn.init.zeros_(module.bias)\n        elif isinstance(module, nn.Embedding):\n            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n    \n    def forward(self, index, targets=None):\n        B, T = index.shape\n\n        tok_embed = self.token_embedding_table(index)\n        pos_embed = self.position_embedding_table(torch.arange(T, device=device))\n        x = tok_embed + pos_embed\n        x = self.blocks(x)\n        x = self.ln_f(x)\n        logits = self.lm_head(x)\n\n\n\n        if targets is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, index, max_new_tokens):\n        for _ in range(max_new_tokens):\n            index_cond = index[:, -block_size:]\n            logits, loss = self.forward(index_cond)\n            logits = logits[:, -1, :]\n            probs = F.softmax(logits, dim=-1)\n            index_next = torch.multinomial(probs, num_samples=1)\n            index = torch.cat((index, index_next), dim=1)\n        return index","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:15:19.687333Z","iopub.execute_input":"2024-07-27T14:15:19.688153Z","iopub.status.idle":"2024-07-27T14:15:19.713004Z","shell.execute_reply.started":"2024-07-27T14:15:19.688121Z","shell.execute_reply":"2024-07-27T14:15:19.712145Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"model = GPTLanguageModel(vocab_size=len(chars))\nmodel = model.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"context = torch.zeros((batch_size, block_size), dtype=torch.long, device=device)\ngenerated_chars = decode(model.generate(context, max_new_tokens=20)[0].tolist())\nprint(generated_chars)","metadata":{"execution":{"iopub.status.busy":"2024-07-27T14:15:20.337106Z","iopub.status.idle":"2024-07-27T14:15:20.337461Z","shell.execute_reply.started":"2024-07-27T14:15:20.337289Z","shell.execute_reply":"2024-07-27T14:15:20.337302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(model.parameters(), lr = learning_rate)\n\nfor iter in range(1, max_iter+1):\n    if iter % eval_iters == 0:\n        losses = estimate_loss()\n        print(f\"Step : {iter}\\tTrain loss : {losses['train']:.3f},\\tVal loss : {losses['val']:.3f}\")\n    \n    xb, yb = get_batch(\"train\")\n    \n    logits, loss = model.forward(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\n    \nprint(loss.item())\ntorch.save(model.state_dict(), \"./\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def user_prompt(model, context=None, max_new_tokens=1000):\n\n    if context is None:\n        user_input = input(\"Enter your prompt: \")\n        context = torch.tensor(encode(user_input), dtype=torch.long, device=device)\n\n    # Generate new tokens\n    generated_index = decode(model.generate(context, max_new_tokens=max_new_tokens)[0].tolist())\n\n    # Print the generated text\n    print(generated_text)\n\n    #return generated_text","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_prompt(model=model, \"hello\")","metadata":{},"execution_count":null,"outputs":[]}]}